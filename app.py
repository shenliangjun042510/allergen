import streamlit as st
import pandas as pd
import json
import time
import re
import os
from collections import defaultdict
import random

import requests
from bs4 import BeautifulSoup

from parser import get_uniprot_id_from_detail_page

from io import StringIO

from st_func import *

@st.cache_data
def load_results(file_path="output.txt"):
    """è§£æ output.txt ä¸­çš„é¢„æµ‹ç»“æœ"""
    results = []
    with open(file_path, encoding='utf-8') as f:
        lines = f.readlines()

    current_desc = None
    current_score = None

    for line in lines:
        if line.startswith("   ğŸ“› åç§°:"):
            current_desc = line.strip().replace("ğŸ“› åç§°:", "").strip()
        elif line.startswith("   ğŸ“Š ç»¼åˆå¾—åˆ†:"):
            score_str = line.strip().replace("ğŸ“Š ç»¼åˆå¾—åˆ†:", "").strip()
            try:
                current_score = float(score_str)
            except ValueError:
                current_score = None

            if current_desc and current_score is not None:
                results.append({
                    "description": current_desc,
                    "score": current_score
                })
                current_desc = None
                current_score = None
    return results


def extract_os(description):
    match = re.search(r'OS=([^=]+?)\s*(?:OX=|GN=|PE=|SV=|$)', description)
    return match.group(1).strip() if match else "Unknown"

def get_genus(species_name):
    return species_name.strip().split()[0]

def parse_allergen_text(path: str) -> pd.DataFrame:
    with open(path, 'r') as f:
        text = f.read()
        
    entries = re.split(r"\n\d+\.\s+", text.strip())
    records = []

    for entry in entries:
        lines = entry.strip().split("\n")
        if not lines:
            continue
        
        record = {
            "id": None,
            "name": None,
            "identity": None,
            "has_8mer_match": None,
            "score": None,
            "mode": None
        }

        # ç¬¬ä¸€è¡Œä¸º ID
        record["id"] = lines[0].strip().split("|")[1]

        for line in lines[1:]:
            line = line.strip()
            if line.startswith("ğŸ“›"):
                record["name"] = extract_os(line.split("ğŸ“› åç§°:")[1].strip())
            elif line.startswith("ğŸ§¬"):
                match = re.search(r"Identity:\s*([\d.]+)", line)
                if match:
                    record["identity"] = float(match.group(1))
            elif line.startswith("ğŸ”—"):
                match = re.search(r"Has 6-mer match:\s*(True|False)", line)
                if match:
                    record["has_8mer_match"] = match.group(1) == "True"
            elif line.startswith("ğŸ“Š"):
                match = re.search(r"ç»¼åˆå¾—åˆ†:\s*([\d.]+)", line)
                if match:
                    record["score"] = float(match.group(1))
            elif line.startswith("ğŸ”"):
                match = re.search(r"åŒ¹é…æ¨¡å¼:\s*(\w+)", line)
                if match:
                    record["mode"] = match.group(1)
        if None in record.values():
            continue
        records.append(record)

    return pd.DataFrame(records)


def summarize_species_dedup_genus(results):
    species_scores = defaultdict(list)

    for r in results:
        os_name = extract_os(r["description"])
        species_scores[os_name].append(r["score"])

    summary = []
    for species, scores in species_scores.items():
        summary.append({
            "species": species,
            "genus": get_genus(species),
            "max_score": max(scores),
            "avg_score": sum(scores) / len(scores),
            "hits": len(scores)
        })

    best_per_genus = {}
    for item in summary:
        genus = item["genus"]
        if genus not in best_per_genus or item["max_score"] > best_per_genus[genus]["max_score"]:
            best_per_genus[genus] = item

    return sorted(best_per_genus.values(), key=lambda x: x["max_score"], reverse=True)

# ========== Streamlit é¡µé¢ ==========
st.set_page_config(page_title="äº¤å‰è¿‡æ•åŸé¢„æµ‹å™¨", layout="wide")
st.title("ğŸ§¬ è›‹ç™½è´¨äº¤å‰è¿‡æ•åŸé¢„æµ‹")

# html, css, javascripts
st.markdown(
    """
    <div style="text-align: center;">
        <img src="https://www.cusabio.com/manage/upload/202109/antibody-cross-reaction.png" width="600"/>
        <p>cross allergen</p>
    </div>
    """,
    unsafe_allow_html=True
)

input_species = st.text_input("ğŸ” è¾“å…¥ç‰©ç§åç§°ï¼ˆä¾‹å¦‚ peanut, shrimp, soyï¼‰ï¼š", value="peanut")
print(f"input species: {input_species}")
top_n = st.slider("ğŸ”¢ æ˜¾ç¤º Top-N ç»“æœ", 5, 20, 10)

predict_button = st.button("ğŸš€ å¼€å§‹é¢„æµ‹")

# ========== ä¸»æµç¨‹ ==========
if predict_button:
    # 1. æœç´¢å¹¶ä¿å­˜è¯¥ç‰©ç§çš„è¿‡æ•åŸ
    os.makedirs("species_cache", exist_ok=True)
    allergen_csv_path = f"species_cache/{input_species}_allergens.csv"

    # 1. ä¼˜å…ˆä» cache è¯»å–ç‰©ç§è¿‡æ•åŸ
    if os.path.exists(allergen_csv_path):
        allergen_df = pd.read_csv(allergen_csv_path)
    else:
        st.info(f"ğŸ” æ­£åœ¨æœç´¢ {input_species} çš„è¿‡æ•åŸ...")
        allergens = search_allergen_org_with_real_uniprot_st(input_species)
        allergen_df = pd.DataFrame(allergens)
        allergen_df.to_csv(allergen_csv_path, index=False, encoding="utf-8")

    # å±•ç¤ºè¿‡æ•åŸåˆ—è¡¨
    st.subheader(f"ğŸ“‹ {input_species} çš„è¿‡æ•åŸåˆ—è¡¨")
    st.dataframe(allergen_df,height=200)

    # ä¸‹è½½æŒ‰é’®
    csv_data = allergen_df.to_csv(index=False).encode("utf-8")
    st.download_button(
        label="ğŸ“¥ ä¸‹è½½è¯¥ç‰©ç§è¿‡æ•åŸåˆ—è¡¨ï¼ˆCSVï¼‰",
        data=csv_data,
        file_name=f"{input_species}_allergens.csv",
        mime="text/csv"
    )

    # 2. äº¤å‰è¿‡æ•åŸé¢„æµ‹
    if os.path.exists(f"result_cache/{input_species}.txt"):
        df = parse_allergen_text(f"result_cache/{input_species}.txt")
    else:
        with st.spinner("ğŸ§  æ­£åœ¨é¢„æµ‹å¯èƒ½çš„äº¤å‰è¿‡æ•åŸç‰©ç§ï¼Œè¯·ç¨å€™..."):
            df = predict_cross_allergen_streamlit(species_name=input_species)
            df = df.sort_values(by="score", ascending=False).reset_index(drop=True)

    # å±•ç¤ºè¿‡æ•åŸåˆ—è¡¨
    st.subheader(f"ğŸ“‹ {input_species} çš„äº¤å‰è¿‡æ•åŸé¢„æµ‹ç»“æœ")
    st.dataframe(df,height=200)

    # ä¸‹è½½æŒ‰é’®
    csv_data = df.to_csv(index=False).encode("utf-8")
    st.download_button(
        label="ğŸ“¥ ä¸‹è½½ç»“æœ CSV",
        data=csv_data,
        file_name=f"{input_species}_cross_allergen_results.csv",
        mime="text/csv"
    )

